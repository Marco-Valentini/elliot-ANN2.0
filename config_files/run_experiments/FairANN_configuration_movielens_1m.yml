experiment:
  dataset: movielens_1m
  data_config:
    strategy: fixed
    train_path: ../data/movielens_1m/filtered_data/0/train.tsv
    test_path: ../data/movielens_1m/filtered_data/0/test.tsv
    side_information:
      - dataloader: ItemPopularityUserActivity
        user_file: ../data/movielens_1m/user_groups_2.tsv
        item_file: ../data/movielens_1m/item_groups_2.tsv
        user_group_file: ../data/movielens_1m/group2_to_users.json
        item_group_file: ../data/movielens_1m/group2_to_items.json
  top_k: 50
  #TODO decidere la divisione in gruppi, se 2 o 4
  evaluation:
    cutoffs: [5, 10, 20]
    simple_metrics: [nDCG,Precision,ItemCoverage,EPC,Gini]
    complex_metrics:
      - metric: BiasDisparityBD
        user_clustering_name: UserActivity
        user_clustering_file: ../data/movielens_1m/user_no_groups.tsv #user_groups_4.tsv
        item_clustering_name: ItemPopularity
        item_clustering_file: ../data/movielens_1m/item_groups_4.tsv #item_no_groups.tsv
      - metric: BiasDisparityBR
        user_clustering_name: UserActivity
        user_clustering_file: ../data/movielens_1m/user_no_groups.tsv #user_groups_4.tsv
        item_clustering_name: ItemPopularity
        item_clustering_file: ../data/movielens_1m/item_groups_4.tsv #item_no_groups.tsv
      - metric: BiasDisparityBS
        user_clustering_name: UserActivity
        user_clustering_file: ../data/movielens_1m/user_no_groups.tsv #user_groups_4.tsv
        item_clustering_name: ItemPopularity
        item_clustering_file: ../data/movielens_1m/item_groups_4.tsv #item_no_groups.tsv
      - metric: REO
        clustering_name: ItemPopularity
        clustering_file: ../data/movielens_1m/item_groups_4.tsv
      - metric: RSP
        clustering_name: ItemPopularity
        clustering_file: ../data/movielens_1m/item_groups_4.tsv
  external_models_path: ../external/models/__init__.py
  models:
    Random:
      meta:
        verbose: True
        save_recs: True
      seed: 42
    external.MostPop:
      meta:
        verbose: True
        save_recs: True
        validation_metric: nDCG@10
    ItemKNN:
      meta:
        verbose: False
        save_recs: False
        validation_metric: nDCG@10
      neighbors: 40 # TODO discutere valori qui
      similarity: [cosine, jaccard, euclidean] # TODO discutere valori qui
      implementation: standard
    UserKNN:
      meta:
        verbose: False
        save_recs: False
        validation_metric: nDCG@10
      neighbors: 40 # TODO discutere valori qui
      similarity: [cosine, jaccard, euclidean] # TODO discutere valori qui
      implementation: standard
    ItemFairANN:
      meta:
        verbose: True
        save_recs: False
        validation_metric: nDCG@10
      neighbors: 50 # TODO discutere valori qui
      similarity: [cosine, jaccard, euclidean] # TODO discutere valori qui
      sampling_strategy: [no_sampling, uniform, weighte_uniform, rank, opt, approx_degree]
      validate: False # TODO questo non lo metterei
      n_hash: 3 # TODO discutere valori qui
      n_tables: 5 # TODO discutere valori qui
      similarity_threshold: 0.3 # TODO questo non lo metterei
    UserFairANN:
      meta:
        verbose: True
        save_recs: False
        validation_metric: nDCG@10
      neighbors: 50 # TODO discutere valori qui
      similarity: [cosine, jaccard, euclidean] # TODO discutere valori qui
      sampling_strategy: [no_sampling, uniform, weighte_uniform, rank, opt, approx_degree]
      validate: False # TODO questo non lo metterei
      n_hash: 3 # TODO discutere valori qui
      n_tables: 5 # TODO discutere valori qui
      similarity_threshold: 0.3 # TODO questo non lo metterei
      #   questi sotto sono gli equivalenti di no_sampling
#    ItemANNLSH:
#      meta:
#        verbose: True
#        save_recs: False
#        validation_metric: nDCG@10
#      neighbors: 50
#      similarity: cosine
#      validate: False
#      n_hash: 3
#      n_tables: 5
#      similarity_threshold: 0.3
#    UserANNLSH:
#      meta:
#        verbose: True
#        save_recs: False
#        validation_metric: nDCG@10
#      neighbors: 50
#      similarity: cosine
#      validate: False
#      n_hash: 3
#      n_tables: 5
#      similarity_threshold: 0.3
    ItemANNfaissLSH:
      meta:
        verbose: True
        save_recs: False
      neighbors: 40 # TODO discutere valori qui
      similarity: cosine #TODO qui potrebbe andare potenzialmente qualsiasi
      nbits: 3 # TODO discutere valori qui
    UserANNfaissLSH:
      meta:
        verbose: True
        save_recs: False
      neighbors: 40 # TODO discutere valori qui
      similarity: cosine #TODO qui potrebbe andare potenzialmente qualsiasi
      nbits: 3 # TODO discutere valori qui
    ItemANNOY:
      meta:
        verbose: True
        save_recs: True
      neighbors: 40
      similarity: angular
      n_trees: 3 # TODO discutere valori qui
      search_k: -1 # TODO discutere valori qui
    UserANNOY:
      meta:
        verbose: True
        save_recs: True
      neighbors: 40
      similarity: [angular, euclidean, manhattan, hamming, dot]
      n_trees: 3 # TODO discutere valori qui
      search_k: -1 # TODO discutere valori qui
    ItemKNNfairness:
      meta:
        verbose: False
        save_recs: False
        validation_metric: nDCG@10
      neighbors: 40 # TODO discutere valori qui
      similarity: cosine #TODO qui potrebbe andare potenzialmente qualsiasi
# qui si pu√≤ scegliere uno solo dei due (loro ne usano uno per volta, non so se vogliamo combinarli noi, io eviterei)
      pre_processing: items
#      post_processing: parity
    UserKNNfairness:
      meta:
        verbose: False
        save_recs: False
        validation_metric: nDCG@10
      neighbors: 40 # TODO discutere valori qui
      similarity: cosine #TODO qui potrebbe andare potenzialmente qualsiasi
      pre_processing: users
#      post_processing: parity
