experiment:
  version: 0.3.1
  backend: tensorflow
  data_config:
    strategy: fixed
    train_path: ../data/{0}/train.dat
    validation_path: ../data/{0}/valid.dat
    test_path: ../data/{0}/test.dat
    side_information:
      - dataloader: KGRec
        mapping: ../data/{0}/ktup_mapping.tsv
        kg_train: ../data/{0}/kg_train.tsv
        kg_dev: ../data/{0}/kg_valid.tsv
        kg_test: ../data/{0}/kg_test.tsv
      - dataloader: KAHFMLoader
        threshold: 0.97
        mapping: ../data/{0}/ktup_mapping.tsv
        kg_train: ../data/{0}/kg_train.tsv
        kg_dev: ../data/{0}/kg_valid.tsv
        kg_test: ../data/{0}/kg_test.tsv
  binarize: True
  dataset: ml1m_ktup
  external_models_path: ../external/models/__init__.py
  top_k: 10
  evaluation:
    cutoffs: [10]
    simple_metrics: [nDCG, Recall, HR]
    relevance_threshold: 0
  gpu: -1 # -1 is not use GPU
  models:
    external.KaVAE:
      meta:
        hyper_max_evals: 1
        hyper_opt_alg: tpe
        validation_rate: 1
        verbose: True
        save_weights: False
        save_recs: False
      lr: 0.001
      epochs: 100
      intermediate_dim: 300
      latent_dim: 100
      batch_size: 128
      dropout_pkeep: 0.8
      reg_lambda: 0
#      lr: [loguniform, -10, -1]
#      epochs: 10
#      intermediate_dim: [uniform,50,300]
#      latent_dim: [uniform,50,300]
#      batch_size: 64
#      dropout_pkeep: 1
#      reg_lambda: [0, 0.01, 0.001]
#    external.KTUP:
#      meta:
#        hyper_max_evals: 1
#        hyper_opt_alg: tpe
#        validation_rate: 1
#        verbose: True
#        save_weights: False
#        save_recs: False
#      learning_rate: 0.001
#      embedding_size: 100
#      l2_lambda: 0.0
#      epochs: 3
#      batch_size: 200
#      joint_ratio: 0.7
#      use_st_gumbel: False
#    KaHFMEmbeddings:
#      meta:
#        hyper_max_evals: 1
#        hyper_opt_alg: tpe
#        validation_rate: 1
#        verbose: True
#        save_weights: False
#        save_recs: False
#        validation_metric: nDCG
#        restore: False
#      loader: KAHFMLoader
#      lr: 0.0001
#      epochs: 100
#      l_b: 0
#      l_w: 0.00025